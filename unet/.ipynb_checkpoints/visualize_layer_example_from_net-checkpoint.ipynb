{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.preprocessing.image import save_img\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Processing filter 0\n",
      "Filter 0 processed in 2s\n",
      "Processing filter 1\n",
      "Filter 1 processed in 2s\n",
      "Processing filter 2\n",
      "Filter 2 processed in 2s\n",
      "Processing filter 3\n",
      "Filter 3 processed in 2s\n",
      "Processing filter 4\n",
      "Filter 4 processed in 2s\n",
      "Processing filter 5\n",
      "Filter 5 processed in 2s\n",
      "Processing filter 6\n",
      "Filter 6 processed in 2s\n",
      "Processing filter 7\n",
      "Filter 7 processed in 2s\n",
      "Processing filter 8\n",
      "Filter 8 processed in 2s\n",
      "Processing filter 9\n",
      "Filter 9 processed in 2s\n",
      "Processing filter 10\n",
      "Filter 10 processed in 2s\n",
      "Processing filter 11\n",
      "Filter 11 processed in 2s\n",
      "Processing filter 12\n",
      "Filter 12 processed in 2s\n",
      "Processing filter 13\n",
      "Filter 13 processed in 3s\n",
      "Processing filter 14\n",
      "Filter 14 processed in 3s\n",
      "Processing filter 15\n",
      "Filter 15 processed in 3s\n",
      "Processing filter 16\n",
      "Filter 16 processed in 3s\n",
      "Processing filter 17\n",
      "Filter 17 processed in 3s\n",
      "Processing filter 18\n",
      "Filter 18 processed in 3s\n",
      "Processing filter 19\n",
      "Filter 19 processed in 3s\n",
      "Processing filter 20\n",
      "Filter 20 processed in 3s\n",
      "Processing filter 21\n",
      "Filter 21 processed in 3s\n",
      "Processing filter 22\n",
      "Filter 22 processed in 3s\n",
      "Processing filter 23\n",
      "Filter 23 processed in 3s\n",
      "Processing filter 24\n",
      "Filter 24 processed in 3s\n",
      "Processing filter 25\n",
      "Filter 25 processed in 3s\n",
      "Processing filter 26\n",
      "Filter 26 processed in 3s\n",
      "Processing filter 27\n",
      "Filter 27 processed in 3s\n",
      "Processing filter 28\n",
      "Filter 28 processed in 3s\n",
      "Processing filter 29\n",
      "Filter 29 processed in 3s\n",
      "Processing filter 30\n",
      "Filter 30 processed in 3s\n",
      "Processing filter 31\n",
      "Filter 31 processed in 3s\n",
      "Processing filter 32\n",
      "Filter 32 processed in 3s\n",
      "Processing filter 33\n",
      "Filter 33 processed in 3s\n",
      "Processing filter 34\n",
      "Filter 34 processed in 3s\n",
      "Processing filter 35\n",
      "Filter 35 processed in 4s\n",
      "Processing filter 36\n",
      "Filter 36 processed in 3s\n",
      "Processing filter 37\n",
      "Filter 37 processed in 3s\n",
      "Processing filter 38\n",
      "Filter 38 processed in 4s\n",
      "Processing filter 39\n",
      "Filter 39 processed in 3s\n",
      "Processing filter 40\n",
      "Filter 40 processed in 3s\n",
      "Processing filter 41\n",
      "Filter 41 processed in 3s\n",
      "Processing filter 42\n",
      "Filter 42 processed in 3s\n",
      "Processing filter 43\n",
      "Filter 43 processed in 3s\n",
      "Processing filter 44\n",
      "Filter 44 processed in 3s\n",
      "Processing filter 45\n",
      "Filter 45 processed in 3s\n",
      "Processing filter 46\n",
      "Filter 46 processed in 4s\n",
      "Processing filter 47\n",
      "Filter 47 processed in 3s\n",
      "Processing filter 48\n",
      "Filter 48 processed in 3s\n",
      "Processing filter 49\n",
      "Filter 49 processed in 4s\n",
      "Processing filter 50\n",
      "Filter 50 processed in 4s\n",
      "Processing filter 51\n",
      "Filter 51 processed in 4s\n",
      "Processing filter 52\n",
      "Filter 52 processed in 4s\n",
      "Processing filter 53\n",
      "Filter 53 processed in 4s\n",
      "Processing filter 54\n",
      "Filter 54 processed in 4s\n",
      "Processing filter 55\n",
      "Filter 55 processed in 4s\n",
      "Processing filter 56\n",
      "Filter 56 processed in 4s\n",
      "Processing filter 57\n",
      "Filter 57 processed in 4s\n",
      "Processing filter 58\n",
      "Filter 58 processed in 4s\n",
      "Processing filter 59\n",
      "Filter 59 processed in 4s\n",
      "Processing filter 60\n",
      "Filter 60 processed in 4s\n",
      "Processing filter 61\n",
      "Filter 61 processed in 4s\n",
      "Processing filter 62\n",
      "Filter 62 processed in 4s\n",
      "Processing filter 63\n",
      "Filter 63 processed in 4s\n"
     ]
    }
   ],
   "source": [
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'c4'\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + K.epsilon())\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "\n",
    "model = load_model('../../modele/unet_on_coco.h5', custom_objects={'mean_iou': mean_iou})\n",
    "print('Model loaded.')\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + K.epsilon())\n",
    "\n",
    "list_of_registere_arr = np.zeros((1, 128, 128, 3), dtype=np.uint8)\n",
    "    \n",
    "registered_arr = np.zeros((480, 360, 3), dtype=np.uint8)\n",
    "\n",
    "kept_filters = []\n",
    "for filter_index in range(64):\n",
    "    # we only scan through the first 12 filters,\n",
    "    # but there are actually 16 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "    \n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "        \n",
    "   \n",
    "    \n",
    "    registered_arr = imread('ziem.jpg')\n",
    "    \n",
    "    registered_lower_res = np.zeros((128, 128, 3), dtype=np.uint8)\n",
    "    \n",
    "    registered_lower_res = resize(registered_arr, (128,128), mode='constant', preserve_range=True)\n",
    "    list_of_registere_arr[0] = registered_lower_res\n",
    "    \n",
    "    input_img_data = (list_of_registere_arr - 0.5) * 20 + 128\n",
    "    \n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        #print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 5\n",
    "print(len(kept_filters) )\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        width_margin = (img_width + margin) * i\n",
    "        height_margin = (img_height + margin) * j\n",
    "        stitched_filters[\n",
    "            width_margin: width_margin + img_width,\n",
    "            height_margin: height_margin + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "save_img('filters/' + layer_name + 'stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
